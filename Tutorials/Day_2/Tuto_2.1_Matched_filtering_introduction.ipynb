{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "D_QUDECR0psB"
   },
   "source": [
    "<img style=\"float: left;padding: 1.3em\" src=\"https://indico.in2p3.fr/event/18313/logo-786578160.png\">  \n",
    "\n",
    "#  Gravitational Wave Open Data Workshop #4\n",
    "\n",
    "\n",
    "## Tutorial 2.1 PyCBC Tutorial, An introduction to matched-filtering\n",
    "\n",
    "We will be using the [PyCBC](http://github.com/ligo-cbc/pycbc) library, which is used to study gravitational-wave data, find astrophysical sources due to compact binary mergers, and study their parameters. These are some of the same tools that the LIGO and Virgo collaborations use to find gravitational waves in LIGO/Virgo data \n",
    "\n",
    "In this tutorial we will walk through how to find a specific signal in LIGO data. We present matched filtering as a cross-correlation, in both the time domain and the frequency domain. In the next tutorial (2.2), we use the method as encoded in PyCBC, which is optimal in the case of Gaussian noise and a known signal model. In reality our noise is not entirely Gaussian, and in practice we use a variety of techniques to separate signals from noise in addition to the use of the matched filter. \n",
    "\n",
    "[Click this link to view this tutorial in Google Colaboratory](https://colab.research.google.com/github/gw-odw/odw-2021/blob/master/Tutorials/Day_2/Tuto_2.1_Matched_filtering_introduction.ipynb)\n",
    "\n",
    "Additional [examples](http://pycbc.org/pycbc/latest/html/#library-examples-and-interactive-tutorials) and module level documentation are [here](http://pycbc.org/pycbc/latest/html/py-modindex.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "VfuWmS4z0psH"
   },
   "source": [
    "## Installation (un-comment and execute only if running on a cloud platform!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-oaVmOkc0psJ",
    "outputId": "d6785c31-f774-45be-8b42-51c4e777b80d"
   },
   "outputs": [],
   "source": [
    "# -- Use the following for Google Colab\n",
    "#! pip install -q 'lalsuite==6.82' 'PyCBC==1.18.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "bkT6oEIq0psO"
   },
   "source": [
    "**Important:** With Google Colab, you may need to restart the runtime after running the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "n1n6Ut_v0psP"
   },
   "source": [
    "## Matched-filtering: Finding well modelled signals in Gaussian noise\n",
    "\n",
    "Matched filtering can be shown to be the optimal method for \"detecting\" _known_ signals in _Gaussian_ noise. We'll explore those two assumptions a little later, but for now let's demonstrate how this works.\n",
    "\n",
    "Let's assume you have a stretch of noise, white noise to start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "YUS9v3eM0psQ"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "import pylab\n",
    "\n",
    "# specify the sample rate.\n",
    "# LIGO raw data is sampled at 16384 Hz (=2^14 samples/second).\n",
    "# It captures signal frequency content up to f_Nyquist = 8192 Hz.\n",
    "# Here, we will make the computation faster by sampling at a lower rate.\n",
    "sample_rate = 1024 # samples per second\n",
    "data_length = 1024 # seconds\n",
    "\n",
    "# Generate a long stretch of white noise: the data series and the time series.\n",
    "data = numpy.random.normal(size=[sample_rate * data_length])\n",
    "times = numpy.arange(len(data)) / float(sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "Lb1qfZuj0psU"
   },
   "source": [
    "And then let's add a gravitational wave signal to some random part of this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycbc.waveform import get_td_waveform\n",
    "\n",
    "# the \"approximant\" (jargon for parameterized waveform family).\n",
    "# IMRPhenomD (a phenomenological Inspiral–Merger–Ringdown wafeform model) is defined in the frequency domain, but we'll get it in the time domain (td).\n",
    "# It runs fast, but it doesn't include effects such as non-aligned component spin, or higher order modes.\n",
    "apx = 'IMRPhenomD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify [many parameters](https://pycbc.org/pycbc/latest/html/pycbc.waveform.html?highlight=get_td_waveform#pycbc.waveform.waveform.get_td_waveform), but here, we'll use defaults for everything except the masses.\n",
    "\n",
    "`get_td_waveform` returns both $h_+$ and $h_{\\times}$, but we'll only use $h_+$ for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp1, _ = get_td_waveform(approximant=apx,\n",
    "                         mass1=10,\n",
    "                         mass2=10,\n",
    "                         delta_t=1.0/sample_rate,\n",
    "                         f_lower=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amplitude of gravitational-wave signals is normally of order $10^{-20}$. To demonstrate our method on white noise with amplitude $O(1)$ we normalize our signal so the cross-correlation of the signal with itself will give a value of 1.\n",
    "\n",
    "In this case we can interpret the cross-correlation of the signal with white noise as a signal-to-noise ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp1 = hp1 / max(numpy.correlate(hp1, hp1, mode='full'))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 869
    },
    "colab_type": "code",
    "id": "8iMaIs1d0psW",
    "outputId": "efce144e-af75-4afd-e4e6-1d41957470cf"
   },
   "outputs": [],
   "source": [
    "# note that in this figure, the waveform amplitude is of order 1.\n",
    "# The duration (for frequency above f_lower=25 Hz) is only 3 or 4 seconds long.\n",
    "# The waveform is \"tapered\": slowly ramped up from zero to full strength, over the first second or so.\n",
    "# It is zero-padded at earlier times.\n",
    "pylab.figure()\n",
    "pylab.title(\"The waveform hp1\")\n",
    "pylab.plot(hp1.sample_times, hp1)\n",
    "pylab.xlabel('Time (s)')\n",
    "pylab.ylabel('Normalized amplitude')\n",
    "\n",
    "# Shift the waveform to start at a random time in the Gaussian noise data.\n",
    "waveform_start = numpy.random.randint(0, len(data) - len(hp1))\n",
    "data[waveform_start:waveform_start+len(hp1)] += 10 * hp1.numpy()\n",
    "\n",
    "pylab.figure()\n",
    "pylab.title(\"Looks like random noise, right?\")\n",
    "pylab.plot(hp1.sample_times, data[waveform_start:waveform_start+len(hp1)])\n",
    "pylab.xlabel('Time (s)')\n",
    "pylab.ylabel('Normalized amplitude')\n",
    "\n",
    "pylab.figure()\n",
    "pylab.title(\"Signal in the data\")\n",
    "pylab.plot(hp1.sample_times, data[waveform_start:waveform_start+len(hp1)])\n",
    "pylab.plot(hp1.sample_times, 10 * hp1)\n",
    "pylab.xlabel('Time (s)')\n",
    "pylab.ylabel('Normalized amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "mmAJqGqH0psZ"
   },
   "source": [
    "To search for this signal we can cross-correlate the signal with the entire dataset -> Not in any way optimized at this point, just showing the method.\n",
    "\n",
    "We will do the cross-correlation in the time domain, once for each time step. It runs slowly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "fi3D6sW70psa",
    "outputId": "34d82dda-e0ed-406f-ec39-58dc4b3d991a"
   },
   "outputs": [],
   "source": [
    "cross_correlation = numpy.zeros([len(data)-len(hp1)])\n",
    "hp1_numpy = hp1.numpy()\n",
    "for i in range(len(data) - len(hp1_numpy)):\n",
    "    cross_correlation[i] = (hp1_numpy * data[i:i+len(hp1_numpy)]).sum()\n",
    "\n",
    "# plot the cross-correlated data vs time. Superimpose the location of the end of the signal;\n",
    "# this is where we should find a peak in the cross-correlation.\n",
    "pylab.figure()\n",
    "times = numpy.arange(len(data) - len(hp1_numpy)) / float(sample_rate)\n",
    "pylab.plot(times, cross_correlation)\n",
    "pylab.plot([waveform_start/float(sample_rate), waveform_start/float(sample_rate)], [-10,10],'r:')\n",
    "pylab.xlabel('Time (s)')\n",
    "pylab.ylabel('Cross-correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection in Colored Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "cafBZG960psc"
   },
   "source": [
    "Here you can see that the largest spike from the cross-correlation comes at the time of the signal. We only really need one more ingredient to describe matched-filtering: \"Colored\" noise (Gaussian noise but with a frequency-dependent variance; white noise has frequency-independent variance). \n",
    "\n",
    "Let's repeat the process, but generate a stretch of data colored with LIGO's zero-detuned--high-power noise curve. We'll use a PyCBC library to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "9Jcw-P_v0psd"
   },
   "outputs": [],
   "source": [
    "# http://pycbc.org/pycbc/latest/html/noise.html\n",
    "import pycbc.noise\n",
    "import pycbc.psd\n",
    "\n",
    "# The color of the noise matches a PSD which you provide:\n",
    "# Generate a PSD matching Advanced LIGO's zero-detuned--high-power noise curve \n",
    "flow = 10.0\n",
    "delta_f = 1.0 / 128\n",
    "flen = int(sample_rate / (2 * delta_f)) + 1\n",
    "psd = pycbc.psd.aLIGOZeroDetHighPower(flen, delta_f, flow)\n",
    "\n",
    "# Generate colored noise\n",
    "delta_t = 1.0 / sample_rate\n",
    "ts = pycbc.noise.noise_from_psd(data_length*sample_rate, delta_t, psd, seed=127)\n",
    "\n",
    "# Estimate the amplitude spectral density (ASD = sqrt(PSD)) for the noisy data \n",
    "# using the \"welch\" method. We'll choose 4 seconds PSD samples that are overlapped 50%\n",
    "seg_len = int(4 / delta_t)\n",
    "seg_stride = int(seg_len / 2)\n",
    "estimated_psd = pycbc.psd.welch(ts,seg_len=seg_len,seg_stride=seg_stride)\n",
    "\n",
    "# plot it:\n",
    "pylab.loglog(estimated_psd.sample_frequencies, estimated_psd, label='estimate')\n",
    "pylab.loglog(psd.sample_frequencies, psd, linewidth=3, label='known psd')\n",
    "pylab.xlim(xmin=flow, xmax=512)\n",
    "pylab.ylim(1e-47, 1e-45)\n",
    "pylab.xlabel('Frequency [Hz]')\n",
    "pylab.ylabel('Power spectral density')\n",
    "pylab.legend()\n",
    "pylab.grid()\n",
    "pylab.show()\n",
    "\n",
    "# add the signal, this time, with a \"typical\" amplitude.\n",
    "ts[waveform_start:waveform_start+len(hp1)] += hp1.numpy() * 1E-20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "rSgmyob_0psf"
   },
   "source": [
    "Then all we need to do is to \"whiten\" both the data, and the template waveform. This can be done, in the frequency domain, by dividing by the PSD. This *can* be done in the time domain as well, but it's more intuitive in the frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "w_v6gzUh0psg"
   },
   "outputs": [],
   "source": [
    "# Generate a PSD for whitening the data\n",
    "from pycbc.types import TimeSeries\n",
    "\n",
    "# The PSD, sampled properly for the noisy data\n",
    "flow = 10.0\n",
    "delta_f = 1.0 / data_length\n",
    "flen = int(sample_rate / (2 * delta_f)) + 1\n",
    "psd_td = pycbc.psd.aLIGOZeroDetHighPower(flen, delta_f, 0)\n",
    "\n",
    "# The PSD, sampled properly for the signal\n",
    "delta_f = sample_rate / float(len(hp1))\n",
    "flen = int(sample_rate / (2 * delta_f)) + 1\n",
    "psd_hp1 = pycbc.psd.aLIGOZeroDetHighPower(flen, delta_f, 0)\n",
    "\n",
    "# The 0th and Nth values are zero. Set them to a nearby value to avoid dividing by zero.\n",
    "psd_td[0] = psd_td[1]\n",
    "psd_td[len(psd_td) - 1] = psd_td[len(psd_td) - 2]\n",
    "# Same, for the PSD sampled for the signal\n",
    "psd_hp1[0] = psd_hp1[1]\n",
    "psd_hp1[len(psd_hp1) - 1] = psd_hp1[len(psd_hp1) - 2]\n",
    "\n",
    "# convert both noisy data and the signal to frequency domain,\n",
    "# and divide each by ASD=PSD**0.5, then convert back to time domain.\n",
    "# This \"whitens\" the data and the signal template. \n",
    "# Multiplying the signal template by 1E-21 puts it into realistic units of strain.\n",
    "data_whitened = (ts.to_frequencyseries() / psd_td**0.5).to_timeseries()\n",
    "hp1_whitened = (hp1.to_frequencyseries() / psd_hp1**0.5).to_timeseries() * 1E-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "d_HLbCCN0psi",
    "outputId": "a5b15941-1ea8-4726-fe80-f08462a8a627"
   },
   "outputs": [],
   "source": [
    "# Now let's re-do the correlation, in the time domain, but with whitened data and template.\n",
    "cross_correlation = numpy.zeros([len(data)-len(hp1)])\n",
    "hp1n = hp1_whitened.numpy()\n",
    "datan = data_whitened.numpy()\n",
    "for i in range(len(datan) - len(hp1n)):\n",
    "    cross_correlation[i] = (hp1n * datan[i:i+len(hp1n)]).sum()\n",
    "\n",
    "# plot the cross-correlation in the time domain. Superimpose the location of the end of the signal.\n",
    "# Note how much bigger the cross-correlation peak is, relative to the noise level,\n",
    "# compared with the unwhitened version of the same quantity. SNR is much higher!\n",
    "pylab.figure()\n",
    "times = numpy.arange(len(datan) - len(hp1n)) / float(sample_rate)\n",
    "pylab.plot(times, cross_correlation)\n",
    "pylab.plot([waveform_start/float(sample_rate), waveform_start/float(sample_rate)],\n",
    "           [(min(cross_correlation))*1.1,(max(cross_correlation))*1.1],'r:')\n",
    "pylab.xlabel('Time (s)')\n",
    "pylab.ylabel('Cross-correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge!\n",
    "\n",
    "* Histogram the whitened time series. Ignoring the outliers associated with the signal, is it a Gaussian? What is the mean and standard deviation? (We have not been careful in normalizing the whitened data properly).\n",
    "* Histogram the above cross-correlation time series. Ignoring the outliers associated with the signal, is it a Gaussian? What is the mean and standard deviation?\n",
    "* Find the location of the peak. (Note that here, it can be positive or negative), and the value of the SNR of the signal (which is the absolute value of the peak value, divided by the standard deviation of the cross-correlation time series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional challenge question 1 (harder):\n",
    "\n",
    "* Repeat this process, using the 10/10 merger signal injected in noisy data, but instead of using a waveform template that matches the signal, try nearby masses (eg, mass1=mass2=5, 7, 9, 11, 13, 15). Plot the SNR vs mass (it should peak at the correct value!). \n",
    "* Careful! Using lower masses (eg, mass1=mass2=1.4 Msun) will not work very well here. Why? (Hint: what is the frequency of the merger and ringdown for the lower-mass signal? What is the Nyquist frequency that we are using in this Tutorial? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional challenge question 2 (harder):\n",
    "\n",
    "* Repeat this process, computing the SNR of a signal injected in noisy data with a template that matches the signal. This time, use a range of masses for both the signal and the template: as low as 5/5, as high as 200/200 or even higher. To make this meaningful, generate the signal at a fixed distance, like 1000 Mpc (distance is one of the input parameters of <a href=\"https://pycbc.org/pycbc/latest/html/pycbc.waveform.html#pycbc.waveform.waveform.get_td_waveform\">get_td_waveform</a>. Plot the SNR vs mass.\n",
    "* You will find that the expected SNR rises with mass (why?), leaks, and then falls at high mass (why?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "DuO18i780pso"
   },
   "source": [
    "### Optimizing a matched-filter\n",
    "\n",
    "That's all that a matched-filter is. A cross-correlation of the data with a template waveform performed as a function of time. This cross-correlation walking through the data is a convolution operation. Convolution operations are more optimally performed in the frequency domain, which becomes a $O(N \\ln N)$ operation, as opposed to the $O(N^2)$ operation shown here. You can also conveniently vary the phase of the signal in the frequency domain, as we will illustrate in the next tutorial. PyCBC implements a frequency-domain matched-filtering engine, which is much faster than the code we've shown here. Let's move to the next tutorial now, where we will demonstrate its use on real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tuto_2.1_Matched_filtering_introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
