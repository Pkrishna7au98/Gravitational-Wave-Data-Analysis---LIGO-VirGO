{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "quA5zQqJ3DkE"
   },
   "source": [
    "<img style=\"float: left;padding: 1.3em\" src=\"https://indico.in2p3.fr/event/18313/logo-786578160.png\">  \n",
    "\n",
    "#  Gravitational Wave Open Data Workshop #4\n",
    "\n",
    "\n",
    "#### Tutorial 3.1:  Parameter estimation for compact object mergers -- Using and interpreting posterior samples\n",
    "\n",
    "This is a simple demonstration to loading and viewing data released in associaton with the publication titled __GWTC-1: A Gravitational-Wave Transient Catalog of Compact Binary Mergers Observed by LIGO and Virgo during the First and Second Observing Runs__ avaliable through [DCC](https://dcc.ligo.org/LIGO-P1800307/public) and [arXiv](https://arxiv.org/abs/1811.12907). This should lead to discussion and interpretation.\n",
    "\n",
    "The data used in these tutorials will be downloaded from the public DCC page [LIGO-P1800370](https://dcc.ligo.org/LIGO-P1800370/public).\n",
    "\n",
    "[Click this link to view this tutorial in Google Colaboratory](https://colab.research.google.com/github/gw-odw/odw-2021/blob/master/Tutorials/Day_3/Tuto_3.1_Parameter_estimation_for_compact_object_mergers.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "taEFmvys3DkG"
   },
   "source": [
    "## Installation (execute only if running on a cloud platform!)Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Z2fAXT1v3DkH",
    "outputId": "1672c2a0-122c-4f03-967e-b911c834b03e"
   },
   "outputs": [],
   "source": [
    "# -- Use the following line for google colab\n",
    "#! pip install -q 'corner==2.0.1' 'bilby==1.0.4' 'astropy==4.0.3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "qrBuraTe3DkK"
   },
   "source": [
    "**Important**: With Google Colab, you may need to restart the runtime after running the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "6uLsysdP3DkL"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "DiR88NzK3DkM"
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import corner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "iBZpF7363DkO"
   },
   "source": [
    "## Get the data\n",
    "\n",
    "Selecting the event, let's pick GW150914."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "id": "sPBQg9cA3DkO",
    "outputId": "5069c0bf-02f6-4fa4-e8c9-d66d66fc2c94"
   },
   "outputs": [],
   "source": [
    "label = 'GW150914'\n",
    "\n",
    "# if you do not have wget installed, simply download manually \n",
    "# https://dcc.ligo.org/LIGO-P1800370/public/GW150914_GWTC-1.hdf5 \n",
    "# from your browser\n",
    "! wget https://dcc.ligo.org/LIGO-P1800370/public/{label}_GWTC-1.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "LlIkUSXc3DkR"
   },
   "outputs": [],
   "source": [
    "posterior_file = './'+label+'_GWTC-1.hdf5'\n",
    "posterior = h5py.File(posterior_file, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "AyfL5UYJ3DkU"
   },
   "source": [
    "### Looking into the file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "tgzznwnT3DkV",
    "outputId": "7dae57fd-d4a2-4acf-b532-44d89e7a2bf3"
   },
   "outputs": [],
   "source": [
    "print('This file contains four datasets: ',posterior.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "bObo647S3DkY"
   },
   "source": [
    "This data file contains several datasets, two using separate models for the gravitational waveform (`IMRPhenomPv2` and `SEOBNRv3` respectively, see the [paper](https://dcc.ligo.org/LIGO-P1800307) for more details). \n",
    "\n",
    "It also contiains a joint dataset, combining equal numbers of samples from each individual model, these datasets are what is shown in the [paper](https://dcc.ligo.org/LIGO-P1800307). \n",
    "\n",
    "Finally, there is a dataset containing samples drawn from the prior used for the analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "D12e3TRs3DkZ",
    "outputId": "251a9744-268c-47e7-c1d7-d0b53c042be7"
   },
   "outputs": [],
   "source": [
    "print(posterior['Overall_posterior'].dtype.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "bM94W-lv3Dkb"
   },
   "source": [
    "Here are some brief descriptions of these parameters and their uses:\n",
    "\n",
    " * `luminosity_distance_Mpc`: luminosity distance [Mpc]\n",
    "\n",
    " * `m1_detector_frame_Msun`: primary (larger) black hole mass (detector frame) [solar mass]\n",
    "\n",
    " * `m2_detector_frame_Msun`: secondary (smaller) black hole mass (detector frame) [solar mass]\n",
    "\n",
    " * `right_ascension`, `declination`: right ascension and declination of the source [rad].\n",
    "\n",
    " * `costheta_jn`: cosine of the angle between line of sight and total angular momentum vector of system.\n",
    "\n",
    " * `spin1`, `costilt1`: primary (larger) black hole spin magnitude (dimensionless) and cosine of the zenith angle between the spin and the orbital angular momentum vector of system.\n",
    "\n",
    " * `spin2`, `costilt2`: secondary (smaller) black hole spin magnitude (dimensionless) and cosine of the zenith angle between the spin and the orbital angular momentum vector of system.\n",
    "\n",
    "A convenient (and pretty) way to load up this array of samples is to use [pandas](https://pandas.pydata.org/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "su0I7kOC3Dkc"
   },
   "outputs": [],
   "source": [
    "samples=pd.DataFrame.from_records(np.array(posterior['Overall_posterior']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "colab_type": "code",
    "id": "j_FO94bB3Dke",
    "outputId": "f9cc5df7-8b9d-4a6c-9a72-81d6bc1b3544"
   },
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "cIAbUy1q3Dkh"
   },
   "source": [
    "Those are all the samples stored in the `Overall` dataset. \n",
    "\n",
    "### Plotting\n",
    "\n",
    "We can plot all of them with, for instance, the [corner](https://corner.readthedocs.io/en/latest/) package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NvG83vQo3Dkh",
    "outputId": "ad13c1f3-f888-4dd4-dd16-fda5a07064f8"
   },
   "outputs": [],
   "source": [
    "corner.corner(samples,labels=['costhetajn',\n",
    "                                'distance [Mpc]',\n",
    "                                'ra',\n",
    "                                'dec',\n",
    "                                'mass1 [Msun]',\n",
    "                                'mass2 [Msun]',\n",
    "                                'spin1',\n",
    "                                'spin2',\n",
    "                                'costilt1',\n",
    "                                'costilt2']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "GglaDuCk3Dkk"
   },
   "source": [
    "Each one and two dimentional histogram are *marginalised* probability density functions. We can manualy select one parameter, say `luminosity distance`, and plot the four different marginalised distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "0ao_u80H3Dkl",
    "outputId": "6725694d-d16e-4f36-8855-197458151aa9"
   },
   "outputs": [],
   "source": [
    "plt.hist(posterior['prior']['luminosity_distance_Mpc'], bins = 100, label='prior', alpha=0.8, density=True)\n",
    "plt.hist(posterior['IMRPhenomPv2_posterior']['luminosity_distance_Mpc'], bins = 100, label='IMRPhenomPv2 posterior', alpha=0.8, density=True)\n",
    "plt.hist(posterior['SEOBNRv3_posterior']['luminosity_distance_Mpc'], bins = 100, label='SEOBNRv3 posterior', alpha=0.8, density=True)\n",
    "plt.hist(posterior['Overall_posterior']['luminosity_distance_Mpc'], bins = 100, label='Overall posterior', alpha=0.8, density=True)\n",
    "plt.xlabel(r'$D_L (Mpc)$')\n",
    "plt.ylabel('Probability Density Function')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "6u5Ba3v53Dkr"
   },
   "source": [
    "### Computing new quantities\n",
    "\n",
    "The masses given are the ones measured at the detector, i.e. in the *detector frame*. To get the actual (*source frame*) masses of the source black holes, we need to correct for the cosmological redshift of the gravitational wave. This forces us to assume a cosmology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "hG06jTn53Dkr"
   },
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from astropy.cosmology import Planck15, z_at_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "lv1EoAny3Dku"
   },
   "source": [
    "We now compute the redshift value for all the samples (using only their distance value). See [astropy.cosmology](http://docs.astropy.org/en/stable/api/astropy.cosmology.z_at_value.html) for implementation details, in particular how to make the following more efficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "RS7AD2dX3Dkv"
   },
   "outputs": [],
   "source": [
    "z = np.array([z_at_value(Planck15.luminosity_distance, dist * u.Mpc) for dist in samples['luminosity_distance_Mpc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "29S-5y-k3Dkx"
   },
   "outputs": [],
   "source": [
    "samples['m1_source_frame_Msun']=samples['m1_detector_frame_Msun']/(1.0+z)\n",
    "samples['m2_source_frame_Msun']=samples['m2_detector_frame_Msun']/(1.0+z)\n",
    "samples['redshift']=z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "lNM077Db3Dk0"
   },
   "source": [
    "And we can plot the marginalised probability density functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "colab_type": "code",
    "id": "QwFJOBJ73Dk1",
    "outputId": "5c4d3542-8c1f-4dcf-b459-2e22ec3bf2bb"
   },
   "outputs": [],
   "source": [
    "corner.corner(samples[['m1_source_frame_Msun','m2_source_frame_Msun','redshift']],labels=['m1 (source)',\n",
    "                                                                                          'm2 (source)',\n",
    "                                                                                          'z']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating credible intervals\n",
    "Let's see how we can use Bilby to calcuate summary statistics for the posterior like the median and 90% credible level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bilby\n",
    "# calculate the detector frame chirp mass\n",
    "mchirp = ((samples['m1_detector_frame_Msun'] * samples['m2_detector_frame_Msun'])**(3./5))/\\\n",
    "         (samples['m1_detector_frame_Msun'] + samples['m2_detector_frame_Msun'])**(1./5)\n",
    "# initialize a SampleSummary object to describe the chirp mass posterior samples\n",
    "chirp_mass_samples_summary = bilby.core.utils.SamplesSummary(samples=mchirp, average='median')\n",
    "print('The median chirp mass = {} Msun'.format(chirp_mass_samples_summary.median))\n",
    "print('The 90% confidence interval for the chirp mass is {} - {} Msun'.format(chirp_mass_samples_summary.lower_absolute_credible_interval,\n",
    "                                                                        chirp_mass_samples_summary.upper_absolute_credible_interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge question\n",
    "Calculate the posterior for the effective spin, which is the mass-weighted component of the binary spin aligned to the orbital angular momentum. It is given by Eqn. 3 of https://journals.aps.org/prx/pdf/10.1103/PhysRevX.9.011001. The z-component of each component spin is defined as $\\chi_{1z} = \\chi_{1}\\cos{\\theta_{1}}$. Then initialize a `SamplesSummary` object for the chi_eff posterior and calculate the mean and the lower and upper absolute credible interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tuto_3.1_Parameter_estimation_for_compact_object_mergers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "igwn-py38",
   "language": "python",
   "name": "igwn-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
